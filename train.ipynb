{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "from sklearn.metrics import roc_auc_score, log_loss, root_mean_squared_error\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, hp, tpe, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from helpers import cfg, supports, load_transform_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CONFIG:\n",
      "---mode > test\n",
      "---mlflow_evals_nbr > 2\n",
      "---booster_rounds > 10\n",
      "---skip_optimization > False\n",
      "---mlflow_artifacts_path > /home/adi/projects/political-engagement-mlops/mlflow/mlruns/poleng\n"
     ]
    }
   ],
   "source": [
    "# initialize configuration\n",
    "# mode=test will minimize parameters (ex: 20 VS 1000 booster runs)\n",
    "# skip_optimization=True will skip model tuning\n",
    "CONFIG = cfg.init_config(mode=\"test\", skip_optimization=False)\n",
    "\n",
    "# output config\n",
    "print(\"---CONFIG:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"---{k} > {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # launch mlflow\n",
    "# mlflow ui --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root mlflow\n",
    "experiment = \"political_engagement\"\n",
    "artifact_location = CONFIG[\"mlflow_artifacts_path\"]\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(experiment)\n",
    "supports.set_mlflow_artifact_location(\n",
    "    \"./mlflow/mlflow.db\",\n",
    "    experiment,\n",
    "    artifact_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ./data/training_data/live_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data = load_transform_predict.Loader.load_live_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training context\n",
    "# get datasets\n",
    "dftrain, dftest = train_test_split(data, test_size=0.2, random_state=99)\n",
    "\n",
    "# get targets\n",
    "ytrain = dftrain[\"political_engagement\"].values\n",
    "ytest = dftest[\"political_engagement\"].values\n",
    "dftrain.drop(columns=[\"political_engagement\"], inplace=True)\n",
    "dftest.drop(columns=[\"political_engagement\"], inplace=True)\n",
    "\n",
    "# vectorize\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = dftrain.to_dict(orient=\"records\")\n",
    "test_dict = dftest.to_dict(orient=\"records\")\n",
    "xtrain = dv.fit_transform(train_dict)\n",
    "xtest = dv.transform(test_dict)\n",
    "\n",
    "# get dmatrix\n",
    "xtrain = xgb.DMatrix(xtrain, label=ytrain)\n",
    "xtest = xgb.DMatrix(xtest, label=ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-logloss:0.55135                             \n",
      "[1]\ttest-logloss:0.53217                             \n",
      "[2]\ttest-logloss:0.52963                             \n",
      "[3]\ttest-logloss:0.52874                             \n",
      "[4]\ttest-logloss:0.52711                             \n",
      "[5]\ttest-logloss:0.52828                             \n",
      "[6]\ttest-logloss:0.52926                             \n",
      "[7]\ttest-logloss:0.52770                             \n",
      "[8]\ttest-logloss:0.52813                             \n",
      "[9]\ttest-logloss:0.52890                             \n",
      "[0]\ttest-logloss:0.65375                                                       \n",
      "[1]\ttest-logloss:0.65348                                                       \n",
      "[2]\ttest-logloss:0.65321                                                       \n",
      "[3]\ttest-logloss:0.65295                                                       \n",
      "[4]\ttest-logloss:0.65268                                                       \n",
      "[5]\ttest-logloss:0.65241                                                       \n",
      "[6]\ttest-logloss:0.65214                                                       \n",
      "[7]\ttest-logloss:0.65188                                                       \n",
      "[8]\ttest-logloss:0.65162                                                       \n",
      "[9]\ttest-logloss:0.65136                                                       \n",
      "100%|██████████| 2/2 [00:00<00:00,  3.33trial/s, best loss: 0.5288979563958918]\n"
     ]
    }
   ],
   "source": [
    "# optimize\n",
    "if not CONFIG[\"skip_optimization\"]:\n",
    "    search_space = {\n",
    "        \"learning_rate\": hp.loguniform(\"learning_rate\", -7, 10),\n",
    "        \"max_depth\": scope.int(hp.quniform(\"max_depth\", 0, 100, 1)),\n",
    "        \"min_child_weight\": hp.loguniform(\"min_child_weight\", -1, 4.6),\n",
    "        \"reg_alpha\": hp.loguniform(\"reg_alpha\", -5, 4.6), \n",
    "        \"scale_pos_weight\": hp.loguniform(\"scale_pos_weight\", 0, 4.6),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"seed\": 99\n",
    "    }\n",
    "\n",
    "    best_result = fmin(\n",
    "        fn=lambda search_space: supports.objective(\n",
    "            search_space=search_space,\n",
    "            xtrain=xtrain,\n",
    "            xtest=xtest,\n",
    "            ytrain=ytrain,\n",
    "            ytest=ytest,\n",
    "            num_boost_round=CONFIG[\"booster_rounds\"]\n",
    "            ),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=CONFIG[\"mlflow_evals_nbr\"],\n",
    "        trials=Trials()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-logloss:0.55135\n",
      "[1]\ttest-logloss:0.53217\n",
      "[2]\ttest-logloss:0.52963\n",
      "[3]\ttest-logloss:0.52874\n",
      "[4]\ttest-logloss:0.52711\n",
      "[5]\ttest-logloss:0.52828\n",
      "[6]\ttest-logloss:0.52926\n",
      "[7]\ttest-logloss:0.52770\n",
      "[8]\ttest-logloss:0.52813\n",
      "[9]\ttest-logloss:0.52890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adi/miniconda3/envs/mlops/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [06:53:51] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5288979563958918, 'status': 'ok'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model with the best params\n",
    "artifacts_path = \"./mlflow\"\n",
    "tags = {\n",
    "        \"author\": \"andrei lupascu\",\n",
    "        \"mode\": CONFIG[\"mode\"]\n",
    "}\n",
    "# update best_result\n",
    "best_result[\"objective\"] = search_space[\"objective\"]\n",
    "best_result[\"seed\"] = search_space[\"seed\"]\n",
    "# format best results (some params need to be cast as int)\n",
    "int_params = [\"max_depth\"]\n",
    "for int_param in int_params:\n",
    "        best_result[int_param] = int(best_result[int_param])\n",
    "\n",
    "supports.objective(\n",
    "     search_space=best_result,\n",
    "     xtrain=xtrain,\n",
    "     xtest=xtest,\n",
    "     ytrain=ytrain,\n",
    "     ytest=ytest,\n",
    "     num_boost_round=CONFIG[\"booster_rounds\"],\n",
    "     tags=tags,\n",
    "     save_artifacts=(True, artifacts_path, dv)\n",
    "     )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
