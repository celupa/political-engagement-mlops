{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "from sklearn.metrics import roc_auc_score, log_loss, root_mean_squared_error\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, hp, tpe, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from misc import init, supports, drift_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CONFIG:\n",
      "---mode > test\n",
      "---mlflow_evals_nbr > 2\n",
      "---booster_rounds > 10\n",
      "---skip_optimization > False\n"
     ]
    }
   ],
   "source": [
    "# initialize configuration\n",
    "# mode=test will minimize parameters (ex: 20 VS 1000 booster runs)\n",
    "# skip_optimization=True will skip model tuning\n",
    "CONFIG = init.init_config(mode=\"test\", skip_optimization=False)\n",
    "\n",
    "# output config\n",
    "print(\"---CONFIG:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"---{k} > {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/adi/projects/political-engagement-mlops/mlruns/1', creation_time=1726041395995, experiment_id='1', last_update_time=1726041395995, lifecycle_stage='active', name='political_engagement', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # launch mlflow\n",
    "# mlflow ui --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(\"political_engagement\")\n",
    "# # enable auto-log\n",
    "# mlflow.xgboost.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = drift_handler.get_data(\"./data/training_data/production_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training context\n",
    "# get datasets\n",
    "dftrain, dftest = train_test_split(data, test_size=0.2, random_state=99)\n",
    "\n",
    "# get targets\n",
    "ytrain = dftrain[\"political_engagement\"].values\n",
    "ytest = dftest[\"political_engagement\"].values\n",
    "dftrain.drop(columns=[\"political_engagement\"], inplace=True)\n",
    "dftest.drop(columns=[\"political_engagement\"], inplace=True)\n",
    "\n",
    "# vectorize\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = dftrain.to_dict(orient=\"records\")\n",
    "test_dict = dftest.to_dict(orient=\"records\")\n",
    "xtrain = dv.fit_transform(train_dict)\n",
    "xtest = dv.transform(test_dict)\n",
    "feature_names = dv.get_feature_names_out().tolist()\n",
    "\n",
    "# get dmatrix\n",
    "xtrain = xgb.DMatrix(xtrain, label=ytrain, feature_names=feature_names)\n",
    "xtest = xgb.DMatrix(xtest, label=ytest, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-logloss:0.68168                             \n",
      "[1]\ttest-logloss:0.66222                             \n",
      "[2]\ttest-logloss:0.64722                             \n",
      "[3]\ttest-logloss:0.63455                             \n",
      "[4]\ttest-logloss:0.62324                             \n",
      "[5]\ttest-logloss:0.61414                             \n",
      "[6]\ttest-logloss:0.60617                             \n",
      "[7]\ttest-logloss:0.59860                             \n",
      "[8]\ttest-logloss:0.59249                             \n",
      "[9]\ttest-logloss:0.58732                             \n",
      "[0]\ttest-logloss:2.29256                                                       \n",
      "[1]\ttest-logloss:15.59105                                                      \n",
      "[2]\ttest-logloss:22.25396                                                      \n",
      "[3]\ttest-logloss:20.00163                                                      \n",
      "[4]\ttest-logloss:20.00163                                                      \n",
      "[5]\ttest-logloss:20.00163                                                      \n",
      "[6]\ttest-logloss:20.00163                                                      \n",
      "[7]\ttest-logloss:20.00163                                                      \n",
      "[8]\ttest-logloss:20.00163                                                      \n",
      "[9]\ttest-logloss:20.00163                                                      \n",
      "100%|██████████| 2/2 [00:00<00:00,  2.38trial/s, best loss: 0.5873230289417607]\n"
     ]
    }
   ],
   "source": [
    "# optimize\n",
    "if not CONFIG[\"skip_optimization\"]:\n",
    "    search_space = {\n",
    "        \"learning_rate\": hp.loguniform(\"learning_rate\", -7, 10),\n",
    "        \"max_depth\": scope.int(hp.quniform(\"max_depth\", 0, 100, 1)),\n",
    "        \"min_child_weight\": hp.loguniform(\"min_child_weight\", -1, 4.6),\n",
    "        \"reg_alpha\": hp.loguniform(\"reg_alpha\", -5, 4.6), \n",
    "        \"scale_pos_weight\": hp.loguniform(\"scale_pos_weight\", 0, 4.6),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"seed\": 99\n",
    "    }\n",
    "\n",
    "    best_result = fmin(\n",
    "        fn=lambda search_space: supports.objective(\n",
    "            search_space=search_space,\n",
    "            xtrain=xtrain,\n",
    "            xtest=xtest,\n",
    "            ytrain=ytrain,\n",
    "            ytest=ytest,\n",
    "            num_boost_round=CONFIG[\"booster_rounds\"]\n",
    "            ),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=CONFIG[\"mlflow_evals_nbr\"],\n",
    "        trials=Trials()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-logloss:0.68168\n",
      "[1]\ttest-logloss:0.66222\n",
      "[2]\ttest-logloss:0.64722\n",
      "[3]\ttest-logloss:0.63455\n",
      "[4]\ttest-logloss:0.62324\n",
      "[5]\ttest-logloss:0.61414\n",
      "[6]\ttest-logloss:0.60617\n",
      "[7]\ttest-logloss:0.59860\n",
      "[8]\ttest-logloss:0.59249\n",
      "[9]\ttest-logloss:0.58732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adi/miniconda3/envs/mlops/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [13:58:54] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5873230289417607, 'status': 'ok'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model with the best params\n",
    "tags = {\n",
    "        \"author\": \"andrei lupascu\",\n",
    "        \"mode\": CONFIG[\"mode\"]\n",
    "}\n",
    "# update best_result\n",
    "best_result[\"objective\"] = search_space[\"objective\"]\n",
    "best_result[\"seed\"] = search_space[\"seed\"]\n",
    "# format best results (some params need to be cast as int)\n",
    "int_params = [\"max_depth\"]\n",
    "for int_param in int_params:\n",
    "        best_result[int_param] = int(best_result[int_param])\n",
    "\n",
    "supports.objective(\n",
    "     search_space=best_result,\n",
    "     xtrain=xtrain,\n",
    "     xtest=xtest,\n",
    "     ytrain=ytrain,\n",
    "     ytest=ytest,\n",
    "     num_boost_round=CONFIG[\"booster_rounds\"],\n",
    "     tags=tags,\n",
    "     save_artifacts=(True, dv)\n",
    "     )\n",
    "\n",
    "# with mlflow.start_run():\n",
    "#     mlflow.set_tags(tags)\n",
    "#     # train model\n",
    "#     booster = xgb.train(\n",
    "#     params=best_result,\n",
    "#     dtrain=xtrain,\n",
    "#     num_boost_round=CONFIG[\"booster_rounds\"],\n",
    "#     evals=[(xtest, \"test\")],\n",
    "#     early_stopping_rounds=50\n",
    "#     )\n",
    "\n",
    "#     # get metrics\n",
    "#     ytrain_pred = booster.predict(xtrain)\n",
    "#     yval_pred = booster.predict(xtest)\n",
    "#     # get auc\n",
    "#     train_auc = roc_auc_score(ytrain, ytrain_pred)\n",
    "#     test_auc = roc_auc_score(ytest, yval_pred)\n",
    "#     # get loss\n",
    "#     train_log_loss = log_loss(ytrain, ytrain_pred)\n",
    "#     test_log_loss = log_loss(ytest, yval_pred)\n",
    "#     # get rmse\n",
    "#     train_rmse = root_mean_squared_error(ytrain, ytrain_pred)\n",
    "#     test_rmse = root_mean_squared_error(ytest, yval_pred)\n",
    "#     # store metrics\n",
    "#     metrics = {\n",
    "#             \"train_auc\": train_auc,\n",
    "#             \"test_auc\": test_auc,\n",
    "#             \"train_log_loss\": train_log_loss,\n",
    "#             \"test_log_loss\": test_log_loss,\n",
    "#             \"train_rmse\": train_rmse,\n",
    "#             \"test_rmse\": test_rmse\n",
    "#     }\n",
    "\n",
    "#         # log metrics\n",
    "#     for name, metric in metrics.items():\n",
    "#         mlflow.log_metric(name, metric)\n",
    "\n",
    "#     # log artifacts  \n",
    "#     with open(f\"./mlflow/{preprocessor_name}.bin\", \"wb\") as fout:\n",
    "#             pickle.dump(dv, fout)\n",
    "#     booster.save_model(f\"./mlflow/{model_name}.xgb\")\n",
    "#     mlflow.log_artifact(f\"./mlflow/{preprocessor_name}.bin\", artifact_path=preprocessor_name)\n",
    "#     mlflow.log_artifact(f\"./mlflow/{model_name}.xgb\", artifact_path=model_name)\n",
    "#     mlflow.log_metric(\"titties\", train_auc)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
