{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "from sklearn.metrics import roc_auc_score, log_loss, root_mean_squared_error\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, hp, tpe, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from helpers import cfg, supports, load_transform_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CONFIG:\n",
      "---mode > test\n",
      "---mlflow_evals_nbr > 2\n",
      "---booster_rounds > 10\n",
      "---skip_optimization > False\n",
      "---mlflow_artifacts_path > /home/adi/projects/political-engagement-mlops/mlflow/mlruns/poleng\n"
     ]
    }
   ],
   "source": [
    "# initialize configuration\n",
    "# mode=test will minimize parameters (ex: 20 VS 1000 booster runs)\n",
    "# skip_optimization=True will skip model tuning\n",
    "CONFIG = cfg.init_config(mode=\"test\", skip_optimization=False)\n",
    "\n",
    "# output config\n",
    "print(\"---CONFIG:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"---{k} > {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # launch mlflow\n",
    "# mlflow ui --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root mlflow\n",
    "experiment = \"political_engagement\"\n",
    "artifact_location = CONFIG[\"mlflow_artifacts_path\"]\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(experiment)\n",
    "supports.set_mlflow_artifact_location(\n",
    "    \"./mlflow/mlflow.db\",\n",
    "    experiment,\n",
    "    artifact_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ./data/training_data/live_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "data = load_transform_predict.Loader.load_live_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training context\n",
    "# get datasets\n",
    "dftrain, dftest = train_test_split(data, test_size=0.2, random_state=99)\n",
    "\n",
    "# get targets\n",
    "ytrain = dftrain[\"political_engagement\"].values\n",
    "ytest = dftest[\"political_engagement\"].values\n",
    "dftrain.drop(columns=[\"political_engagement\"], inplace=True)\n",
    "dftest.drop(columns=[\"political_engagement\"], inplace=True)\n",
    "\n",
    "# vectorize\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = dftrain.to_dict(orient=\"records\")\n",
    "test_dict = dftest.to_dict(orient=\"records\")\n",
    "xtrain = dv.fit_transform(train_dict)\n",
    "xtest = dv.transform(test_dict)\n",
    "\n",
    "# get dmatrix\n",
    "xtrain = xgb.DMatrix(xtrain, label=ytrain)\n",
    "xtest = xgb.DMatrix(xtest, label=ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-logloss:0.55135                             \n",
      "[1]\ttest-logloss:0.53217                             \n",
      "[2]\ttest-logloss:0.52963                             \n",
      "[3]\ttest-logloss:0.52874                             \n",
      "[4]\ttest-logloss:0.52711                             \n",
      "[5]\ttest-logloss:0.52828                             \n",
      "[6]\ttest-logloss:0.52926                             \n",
      "[7]\ttest-logloss:0.52770                             \n",
      "[8]\ttest-logloss:0.52813                             \n",
      "[9]\ttest-logloss:0.52890                             \n",
      "[0]\ttest-logloss:0.65375                                                       \n",
      "[1]\ttest-logloss:0.65348                                                       \n",
      "[2]\ttest-logloss:0.65321                                                       \n",
      "[3]\ttest-logloss:0.65295                                                       \n",
      "[4]\ttest-logloss:0.65268                                                       \n",
      "[5]\ttest-logloss:0.65241                                                       \n",
      "[6]\ttest-logloss:0.65214                                                       \n",
      "[7]\ttest-logloss:0.65188                                                       \n",
      "[8]\ttest-logloss:0.65162                                                       \n",
      "[9]\ttest-logloss:0.65136                                                       \n",
      "100%|██████████| 2/2 [00:00<00:00,  3.33trial/s, best loss: 0.5288979563958918]\n"
     ]
    }
   ],
   "source": [
    "# optimize\n",
    "if not CONFIG[\"skip_optimization\"]:\n",
    "    search_space = {\n",
    "        \"learning_rate\": hp.loguniform(\"learning_rate\", -7, 10),\n",
    "        \"max_depth\": scope.int(hp.quniform(\"max_depth\", 0, 100, 1)),\n",
    "        \"min_child_weight\": hp.loguniform(\"min_child_weight\", -1, 4.6),\n",
    "        \"reg_alpha\": hp.loguniform(\"reg_alpha\", -5, 4.6), \n",
    "        \"scale_pos_weight\": hp.loguniform(\"scale_pos_weight\", 0, 4.6),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"seed\": 99\n",
    "    }\n",
    "\n",
    "    best_result = fmin(\n",
    "        fn=lambda search_space: supports.objective(\n",
    "            search_space=search_space,\n",
    "            xtrain=xtrain,\n",
    "            xtest=xtest,\n",
    "            ytrain=ytrain,\n",
    "            ytest=ytest,\n",
    "            num_boost_round=CONFIG[\"booster_rounds\"]\n",
    "            ),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=CONFIG[\"mlflow_evals_nbr\"],\n",
    "        trials=Trials()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttest-logloss:0.55135\n",
      "[1]\ttest-logloss:0.53217\n",
      "[2]\ttest-logloss:0.52963\n",
      "[3]\ttest-logloss:0.52874\n",
      "[4]\ttest-logloss:0.52711\n",
      "[5]\ttest-logloss:0.52828\n",
      "[6]\ttest-logloss:0.52926\n",
      "[7]\ttest-logloss:0.52770\n",
      "[8]\ttest-logloss:0.52813\n",
      "[9]\ttest-logloss:0.52890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adi/miniconda3/envs/mlops/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [06:53:51] WARNING: /workspace/src/c_api/c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5288979563958918, 'status': 'ok'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model with the best params\n",
    "artifacts_path = \"./mlflow\"\n",
    "tags = {\n",
    "        \"author\": \"andrei lupascu\",\n",
    "        \"mode\": CONFIG[\"mode\"]\n",
    "}\n",
    "# update best_result\n",
    "best_result[\"objective\"] = search_space[\"objective\"]\n",
    "best_result[\"seed\"] = search_space[\"seed\"]\n",
    "# format best results (some params need to be cast as int)\n",
    "int_params = [\"max_depth\"]\n",
    "for int_param in int_params:\n",
    "        best_result[int_param] = int(best_result[int_param])\n",
    "\n",
    "supports.objective(\n",
    "     search_space=best_result,\n",
    "     xtrain=xtrain,\n",
    "     xtest=xtest,\n",
    "     ytrain=ytrain,\n",
    "     ytest=ytest,\n",
    "     num_boost_round=CONFIG[\"booster_rounds\"],\n",
    "     tags=tags,\n",
    "     save_artifacts=(True, artifacts_path, dv)\n",
    "     )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metrics import ColumnDriftMetric, DatasetDriftMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_setup = load_transform_predict.Predictor()\n",
    "live_data = prediction_setup.live_data.copy()\n",
    "\n",
    "prod_batch = pd.read_parquet(\"data/batch_data/testing_batches/prod_data_batch_1.parquet\")\n",
    "new_batch = pd.read_parquet(\"data/batch_data/testing_batches/new_data_batch_1.parquet\")\n",
    "prod_batch.drop(columns=\"subject_id\", inplace=True)\n",
    "new_batch.drop(columns=\"subject_id\", inplace=True)\n",
    "\n",
    "prod_batch = prediction_setup.predict(prod_batch)\n",
    "new_batch = prediction_setup.predict(new_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [col for col in live_data.columns if live_data[col].dtype == \"object\"]\n",
    "num_cols = [col for col in live_data.columns if live_data[col].dtype != \"object\"]\n",
    "all_cols = cat_cols + num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = ColumnMapping(\n",
    "    target=None,\n",
    "    prediction=\"prediction\",\n",
    "    numerical_features=num_cols,\n",
    "    categorical_features=cat_cols\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = Report(metrics=[\n",
    "    ColumnDriftMetric(column_name=\"prediction\"),\n",
    "    DatasetDriftMetric(columns=all_cols, drift_share=0.1)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [prod_batch, new_batch]\n",
    "report.run(\n",
    "    reference_data=live_data, \n",
    "    current_data=test_data[1], \n",
    "    column_mapping=column_mapping\n",
    "    )\n",
    "# report.show(mode=\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Prediction Drift Detected: \n",
      "Target name: prediction\n",
      "Test used: Wasserstein distance (normed)\n",
      "Test threshold: 0.1\n",
      "Test score: 0.20168579624732844\n",
      "\n",
      "\n",
      "---Dataset Drift Detected: \n",
      "Columns drifted: 5\n",
      "Drift threshold: 0.1\n",
      "Drift Share: 0.15151515151515152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = report.as_dict()\n",
    "\n",
    "pred_drift_results = results[\"metrics\"][0]\n",
    "pred_drift_status = pred_drift_results[\"result\"][\"drift_detected\"]\n",
    "pred_drift_col = pred_drift_results[\"result\"][\"column_name\"]\n",
    "pred_drift_test = pred_drift_results[\"result\"][\"stattest_name\"]\n",
    "pred_drift_threshold = pred_drift_results[\"result\"][\"stattest_threshold\"]\n",
    "pred_drift_score = pred_drift_results[\"result\"][\"drift_score\"]\n",
    "\n",
    "dataset_drift_results = results[\"metrics\"][1]\n",
    "dataset_drift_status = dataset_drift_results[\"result\"][\"dataset_drift\"]\n",
    "dataset_drift_columns = dataset_drift_results[\"result\"][\"number_of_drifted_columns\"]\n",
    "dataset_drift_treshold = dataset_drift_results[\"result\"][\"drift_share\"]\n",
    "dataset_drift_share = dataset_drift_results[\"result\"][\"share_of_drifted_columns\"]\n",
    "\n",
    "prediction_drift_warning = f\"\"\"---Prediction Drift Detected: \n",
    "Target name: {pred_drift_col}\n",
    "Test used: {pred_drift_test}\n",
    "Test threshold: {pred_drift_threshold}\n",
    "Test score: {pred_drift_score}\n",
    "\"\"\"\n",
    "dataset_drift_warning = f\"\"\"---Dataset Drift Detected: \n",
    "Columns drifted: {dataset_drift_columns}\n",
    "Drift threshold: {dataset_drift_treshold}\n",
    "Drift Share: {dataset_drift_share}\n",
    "\"\"\"\n",
    "\n",
    "if (pred_drift_status + dataset_drift_status) > 0:\n",
    "    print(prediction_drift_warning)\n",
    "    print()\n",
    "    print(dataset_drift_warning)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
