{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_extraction import DictVectorizer \n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, hp, tpe, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from misc import init, supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize configuration\n",
    "# mode=test will minimize parameters (ex: 20 VS 1000 booster runs)\n",
    "# skip_run=True will skip model tuning\n",
    "CONFIG = init.init_config(mode=\"test\", skip_run=True)\n",
    "\n",
    "# output config\n",
    "print(\"---CONFIG:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"---{k} > {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # launch mlflow\n",
    "# mlflow ui --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root mlflow\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow/mlflow.db\")\n",
    "mlflow.set_experiment(\"political_engagement\")\n",
    "# enable auto-log\n",
    "mlflow.xgboost.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_parquet(\"data/custom_wvs7_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training context\n",
    "# get datasets\n",
    "dftrain, dftest = train_test_split(data, test_size=0.2, random_state=99)\n",
    "\n",
    "# get targets\n",
    "ytrain = dftrain[\"political_engagement\"].values\n",
    "ytest = dftest[\"political_engagement\"].values\n",
    "dftrain.drop(columns=[\"political_engagement\"], inplace=True)\n",
    "dftest.drop(columns=[\"political_engagement\"], inplace=True)\n",
    "\n",
    "# vectorize\n",
    "dv = DictVectorizer(sparse=False)\n",
    "train_dict = dftrain.to_dict(orient=\"records\")\n",
    "test_dict = dftest.to_dict(orient=\"records\")\n",
    "xtrain = dv.fit_transform(train_dict)\n",
    "xtest = dv.transform(test_dict)\n",
    "feature_names = dv.get_feature_names_out().tolist()\n",
    "\n",
    "# get dmatrix\n",
    "xtrain = xgb.DMatrix(xtrain, label=ytrain, feature_names=feature_names)\n",
    "xtest = xgb.DMatrix(xtest, label=ytest, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize\n",
    "if not CONFIG[\"skip_run\"]:\n",
    "    search_space = {\n",
    "        \"learning_rate\": hp.loguniform(\"learning_rate\", -7, 10),\n",
    "        \"max_depth\": scope.int(hp.quniform(\"max_depth\", 0, 100, 1)),\n",
    "        \"min_child_weight\": hp.loguniform(\"min_child_weight\", -1, 4.6),\n",
    "        \"reg_alpha\": hp.loguniform(\"reg_alpha\", -5, 4.6), \n",
    "        \"scale_pos_weight\": hp.loguniform(\"scale_pos_weight\", 0, 4.6),\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"seed\": 99\n",
    "    }\n",
    "\n",
    "    best_result = fmin(\n",
    "        fn=lambda search_space: supports.objective(\n",
    "            search_space=search_space,\n",
    "            xtrain=xtrain,\n",
    "            xtest=xtest,\n",
    "            ytrain=ytrain,\n",
    "            ytest=ytest,\n",
    "            num_boost_round=CONFIG[\"booster_rounds\"]\n",
    "            ),\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=CONFIG[\"mlflow_evals_nbr\"],\n",
    "        trials=Trials()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model from prod run\n",
    "if CONFIG[\"mode\"] != \"test\":\n",
    "    # define tag names (model & author) \n",
    "    model_prefix = \"poleng\"\n",
    "    model_algo = \"xgb\"\n",
    "    # yymmddhhmmss\n",
    "    model_creation_time = datetime.now().strftime(\"%y%m%d%H%M%S\")\n",
    "    model_name = f\"{model_prefix}_{model_algo}_{model_creation_time}\"\n",
    "    author = \"andrei lupascu\"\n",
    "    tags = {\n",
    "            \"model\": model_name,\n",
    "            \"author\": author\n",
    "    }\n",
    "    # update best_result\n",
    "    best_result[\"objective\"] = search_space[\"objective\"]\n",
    "    best_result[\"seed\"] = search_space[\"seed\"]\n",
    "    # format best results (some params need to be cast as int)\n",
    "    int_params = [\"max_depth\"]\n",
    "    for int_param in int_params:\n",
    "        best_result[int_param] = int(best_result[int_param])\n",
    "\n",
    "    with mlflow.start_run():\n",
    "            mlflow.set_tags(tags)\n",
    "\n",
    "            # train model\n",
    "            booster = xgb.train(\n",
    "            params=best_result,\n",
    "            dtrain=xtrain,\n",
    "            num_boost_round=CONFIG[\"booster_rounds\"],\n",
    "            evals=[(xtest, \"test\")],\n",
    "            early_stopping_rounds=50\n",
    "            )\n",
    "\n",
    "            # predict\n",
    "            ypred = booster.predict(xtest)\n",
    "            lg_loss = log_loss(ytest, ypred)\n",
    "\n",
    "            # log artifacts and metrics \n",
    "            with open(\"./mlflow/preprocessor.bin\", \"wb\") as fout:\n",
    "                    pickle.dump(dv, fout)\n",
    "            mlflow.log_artifact(\"./mlflow/preprocessor.bin\", artifact_path=\"preprocessor\")\n",
    "            booster.save_model(\"./mlflow/model.xgb\")\n",
    "            mlflow.xgboost.log_model(booster, artifact_path=\"model\")\n",
    "            mlflow.log_metric(\"test_log_loss\", lg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
