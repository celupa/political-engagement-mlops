{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "prod_data = pd.read_parquet(\"../data/training_data/production_data.parquet\")\n",
    "new_data = pd.read_parquet(\"../data/training_data/new_data/new_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle data\n",
    "sprod_data = prod_data.sample(frac=1).reset_index(drop=True)\n",
    "snew_data = new_data.sample(frac=1).reset_index(drop=True)\n",
    "df_dict = {\"prod_data\" : sprod_data, \n",
    "           \"new_data\": snew_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = 3\n",
    "\n",
    "for df_name, df in df_dict.items():\n",
    "    lower_bound = 0\n",
    "    upper_bound = int(round(len(df) / splits, 0))\n",
    "\n",
    "    for i in range(splits):\n",
    "        batch_name = f\"{df_name}_batch_{i + 1}.parquet\"\n",
    "        subset = df.iloc[lower_bound:upper_bound].copy()\n",
    "        # link subject ID\n",
    "        subset[\"subject_id\"] = [str(uuid.uuid4()) for i in range(len(subset))]\n",
    "        # updates slices\n",
    "        lower_bound = upper_bound\n",
    "        upper_bound += upper_bound \n",
    "        # export batches\n",
    "        subset.to_parquet(f\"../data/batches/{batch_name}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate dump_dates\n",
    "# date_range = list(pd.date_range(start=\"2024-01-01\", end=\"2024-12-31\", freq=\"MS\"))\n",
    "\n",
    "# # write batches\n",
    "# lower_bound = 0\n",
    "# # define the slices (12 months)\n",
    "# upper_bound = threshold = len(sdata) / 12\n",
    "\n",
    "# for idx, vals in enumerate(date_range):\n",
    "#     # assign dates by slices\n",
    "#     sdata.loc[lower_bound:upper_bound, \"dump_date\"] = vals\n",
    "#     # udpate index ranges\n",
    "#     lower_bound += threshold\n",
    "#     upper_bound += threshold or None\n",
    "\n",
    "# # output batches\n",
    "# for date in list(sdata.dump_date.unique()):\n",
    "#     data_path = f\"./data/batches/wvs7_{date.date()}.parquet\"\n",
    "#     batch_data = sdata[sdata.dump_date == date].copy()\n",
    "#     batch_data.drop(columns=[\"dump_date\", \"political_engagement\"], inplace=True)\n",
    "#     batch_data[\"subject_id\"] = [str(uuid.uuid4()) for i in range(len(batch_data))]\n",
    "#     batch_data.to_parquet(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
