{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import xgboost as xgb\n",
    "\n",
    "from typing import Tuple\n",
    "# import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # launch mlflow\n",
    "# # mlflow ui --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root mlflow\n",
    "# mlflow.set_tracking_uri(\"sqlite:///mlflow/mlflow.db\")\n",
    "# mlflow.set_experiment(\"political_engagement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # retrieve best model\n",
    "# client = mlflow.MlflowClient(tracking_uri=mlflow.get_tracking_uri())\n",
    "\n",
    "# best_model = client.search_runs(\n",
    "#     experiment_ids=\"1\",\n",
    "#     run_view_type=mlflow.entities.ViewType.ACTIVE_ONLY,\n",
    "#     max_results=1,\n",
    "#     order_by=[\"metrics.test_log_loss ASC\"]\n",
    "# )[0]\n",
    "\n",
    "# model_id = best_model.info.run_id\n",
    "# model_path = f\"runs:/{model_id}/model\"\n",
    "model = xgb.Booster()\n",
    "model.load_model(\"./mlflow/model.xgb\")\n",
    "\n",
    "# get preprocessor \n",
    "with open(\"./mlflow/preprocessor.bin\", \"rb\") as fin:\n",
    "    dv = pickle.load(fin)\n",
    "\n",
    "# load batch\n",
    "batch = pd.read_parquet(\"data/batches/wvs7_2024-01-01.parquet\")\n",
    "batch_dict = batch.to_dict(orient=\"records\")\n",
    "batch_set = dv.transform(batch_dict)\n",
    "batch_set = xgb.DMatrix(batch_set)\n",
    "\n",
    "# predict (0=subject doesn't need intervention (-), 1=subject could benefit from intervention (CONTACT))\n",
    "batch[\"prediction\"] = np.round(model.predict(batch_set)).astype(int)\n",
    "batch[\"prediction\"] = batch.prediction.replace([0, 1], [\"-\", \"CONTACT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_artifacts(model_path: str, vectorizer_path: str) -> Tuple[xgb.Booster, DictVectorizer]:\n",
    "    \"\"\"Load the latest xgb model and the related vectorizer.\"\"\"\n",
    "\n",
    "    model = xgb.Booster()\n",
    "    model.load_model(model_path)\n",
    "\n",
    "    with open(vectorizer_path, \"rb\") as fin:\n",
    "        dv = pickle.load(fin)\n",
    "\n",
    "    return model, dv \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dmatrix(df: pd.DataFrame, dv: DictVectorizer) -> pd.DataFrame:\n",
    "    \"\"\"Get the XGB DMatrix of a dataframe.\"\"\"\n",
    "\n",
    "    df_dict = df.to_dict(orient=\"records\")\n",
    "    df_vect = dv.transform(df_dict)\n",
    "    df_xgbdm = xgb.DMatrix(df_vect)\n",
    "    \n",
    "    return df_xgbdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "        model_path: str,\n",
    "        vectorizer_path: str, \n",
    "        new_batches_folder_path: str,\n",
    "        predictions_output_path: str\n",
    "        ) -> pd.DataFrame:\n",
    "    \"\"\"Make predictions for new batches.\"\"\"\n",
    "\n",
    "    batch_dict = {}\n",
    "    model, dv = load_artifacts(model_path, vectorizer_path)\n",
    "\n",
    "    for batch in os.listdir(new_batches_folder_path):\n",
    "        # label data\n",
    "        new_batch_path = f\"{new_batches_folder_path}/{batch}\"\n",
    "        batch_name = batch.split(\".\")[0]\n",
    "        output_batch_name = f\"{batch_name}_predicted.parquet\"\n",
    "        predicted_batch_path = f\"{predictions_output_path}/{output_batch_name}\"\n",
    "        # read data and wrangle data\n",
    "        print(f\"Reading: {new_batch_path}\")\n",
    "        df = pd.read_parquet(new_batch_path)\n",
    "        print(\"Predicting...\")\n",
    "        df_dmat = get_dmatrix(df, dv)\n",
    "        # predict (0=subject doesn't need intervention (-), 1=subject could benefit from intervention (CONTACT))\n",
    "        df[\"prediction\"] = np.round(model.predict(df_dmat)).astype(int)\n",
    "        df[\"prediction\"] = df.prediction.replace([0, 1], [\"-\", \"CONTACT\"])\n",
    "        # make things easier for the agents by only keeping the target subjects\n",
    "        df = df[df.prediction == \"CONTACT\"]\n",
    "        # output predicted batch\n",
    "        print(f\"Writing predictions to: {predicted_batch_path}\")\n",
    "        df.to_parquet(predicted_batch_path, index=False)\n",
    "        # remove new batch\n",
    "        os.remove(new_batch_path)\n",
    "        # store predictions (troubleshooting)\n",
    "        batch_dict[output_batch_name] = df\n",
    "\n",
    "    return batch_dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: ./data/new_batches/wvs7_2024-01-01.parquet\n",
      "Predicting...\n",
      "Writing predictions to: ./data/predictions/wvs7_2024-01-01_predicted.parquet\n",
      "Reading: ./data/new_batches/wvs7_2024-02-01.parquet\n",
      "Predicting...\n",
      "Writing predictions to: ./data/predictions/wvs7_2024-02-01_predicted.parquet\n"
     ]
    }
   ],
   "source": [
    "d = predict(\n",
    "    \"./mlflow/model.xgb\",\n",
    "    \"./mlflow/preprocessor.bin\",\n",
    "    \"./data/new_batches\",\n",
    "    \"./data/predictions\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
